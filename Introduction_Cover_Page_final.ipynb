{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Standardized Essays are utilized all across the country; from SATs to AP exams, a majority of these contain structured essay prompts. As technology advances, we look to incorporate these improvements into current essay grading processes. Our team at Harvard's Data Science Course utilizes current Machine Learning and Neural Network practices to analyze a dataset of approximately 13,000 essays that can replicate the results of graders across the country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data was gathered from Kaggle for The Hewlett Foundation: Automatic Essay Scoring competition - https://www.kaggle.com/c/asap-aes.\n",
    "\n",
    "Before analyzing the data, we logically decided what features will impact the quality of an essay. We came up with six features:\n",
    "\n",
    "1. Essay Length: How much content are they putting out?\n",
    "2. Average Sentence Length: Are the sentences short and concise or long and convoluted?\n",
    "3. Average Word Length: Are they using a sophisticated vocabulary?\n",
    "4. Essay Sentiment: Does positivity or negativity affect the grade of an essay?\n",
    "5. Grammar Mistakes: How often is the author making grammar mistakes?\n",
    "6. Spelling Mistakes: How often is the author making spelling mistakes?\n",
    "\n",
    "These six key features will allow us to gain some insight into what is happening in our data. to calculate this, the **TextBlob** package was used. The plot below showcases how each of the features above affect the grade the student receives. As an example, we have only displayed the trends for Essay Set 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "<img src=\"Essay1Features.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we decided to use word2vec to clean and transform our essays. word2vec is a package created by Google that converts text to a vector representation to the size of one's choosing and trained on text of our choosing. **word2vec** is the current standard for essentially a dimensionality reduction for text. The lower space groups similar words together, which improves modeling for both supervised and unsupervised learning methods. \n",
    "\n",
    "Below is an example of a Principal Component Analysis plot of the vectorized word - \"time\". We examine the 25 nearest neighbors of the word time. What's interesting are the clusters that form together. \n",
    "\n",
    "In lower left corner of the plot i.e. hours, days, weeks, years. This is all decided by context of the words! A few other clusters are activities such as exercising, enjoying, outdoors - in the lower right corner of the graph. What's most interesting is the top most clusters. the words patience, patient cluster together as nearest neighbours for time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "<img src=\"wordembedding.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sections, we looked at both traditional classification methods and sophisticated deep learning methods and compared the results. The models we will be using are:\n",
    "- Logistic Regression (Log Reg)\n",
    "- K Nearest Neighbors (KNN)\n",
    "- Support Vector Machines (SVM)\n",
    "- Random Forest (RF)\n",
    "- Feedforward Neural Network (NN)\n",
    "\n",
    "We chose to work with methods thoroughly discussed within this course to apply our methods to real world problems. Additionally, we looked to dabble with more modern techniques so utilized Neural Networks tackle this problem as well.  Neural networks are now the state of art machine learning method, and we're hoping this would be a useful tool for this task. For our analysis, we utilized **sklearn** and **tensorflow** to build our models. \n",
    "\n",
    "To compare each model, we will be using Spearman's Rho as our primary metric. This allows us to compare how two variables score a specific data set. In our case, we will be comparing the scores of a human grader and the scores our models have produced. More information can be found here: https://statistics.laerd.com/statistical-guides/spearmans-rank-order-correlation-statistical-guide.php\n",
    "\n",
    "Since we foresee this algorithm being utilized on a larger scale, it is imperitive that we analyze the computation time when comparing classification methods. The **time** package will be used for this calculation. Below we see how each of our models compare in terms of performance and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "<img src=\"Conclusion.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that KNN, SVM, RF and NN all are high performers but we see a wide range in computation time. Given the problem statement is to create the best predictor of grades, Neural Networks out performs all other classifiers in Spearman's Rho. Computation time is important and we can see that KNN has fairly high accuracy with low computation time, where its computation time is 8 times less than Neural Network. Although, we know that computation time is important for machine learning and data science, we believe that for sensitive tasks such as this accuracy should be more heavily weighted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that a simple Feed Forward Neural Network is the best model in predicting the grade of a neural network. We got a high Spearman's Rho of 0.93 with our achitecture. For future work, we would like to explore more complex deep learning methods such as LSTM, RNN, etc for this problem. Those methods work well for Natural Language Processing tasks such as this one. We would have liked to compare our scores to the Kaggle competition, but because there was no released test set, we decided to use Spearman's Rho instead of the Kaggle metric of Cohen's Kappa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to thank our professors Pavlos Protopapas, Kevin Rader, Weiwei Pan, and our TF Yoon Kim. Thank you for your timley responses and constructive criticism along the milestones of this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Neural Networks for Automated Essay Grading: https://cs224d.stanford.edu/reports/huyenn.pdf\n",
    "- Automatic Text Scoring using Neural Networks: https://da352.user.srcf.net/publications/acl2016.pdf\n",
    "- A Neural Approach to Automated Essay Scoring:\n",
    "- Predicting Grammaticality on an Ordinal Scale: http://aclweb.org/anthology/P/P14/P14-2029.pdf\n",
    "- Automated essay scoring by maximizing human-machine agreement: http://www.aclweb.org/anthology/D13-1180\n",
    "- Task-independent features for automated essay grading: http://www.aclweb.org/anthology/W/W15/W15-0626.pdf\n",
    "- Automated Essay Scoring with E-rater: https://www.ets.org/Media/Research/pdf/RR-04-45.pdf\n",
    "- Automatic Essay Assessment: https://cmap.helsinki.fi/rid=1G5ND4FFJ-1JST8T7-1YY/automatic_essay_assessment.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
